{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTrg-7Jy86au"
   },
   "source": [
    "# Image Compression using Autoencoders with BPSK\n",
    "\n",
    "This code is provided as supplementary material of the lecture Machine Learning and Optimization in Communications (MLOC).<br>\n",
    "\n",
    "This code illustrates\n",
    "* joint compression and error protection of images by auto-encoders\n",
    "* generation of BPSK symbols using stochastic quantizers and transmission over a binary symmetric channel\n",
    "* sweep values over range of block lengths and channel error values to get a plot (attention! lengthy execution time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H2-C3vb86az"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkAKgzix86a_"
   },
   "source": [
    "Import and load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DoWkUm286bB"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# only load the images, we are not interested in the training data\n",
    "(x_train, _),(x_test, _) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "\n",
    "x_test_flat = np.array([np.reshape(x_test[k,:,:], image_size*image_size) for k in range(x_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "giKk3fuN86bI",
    "outputId": "294de44e-0b9e-48d4-9a55-025de9dbaf10"
   },
   "outputs": [],
   "source": [
    "#print 8 random images\n",
    "plt.figure(figsize=(16,2))\n",
    "for k in range(8):\n",
    "    plt.subplot(1,8,k+1)\n",
    "    plt.imshow(x_train[np.random.randint(x_train.shape[0])], interpolation='nearest', cmap='binary')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "33pXGzDZ86bS",
    "outputId": "f7800873-9c2a-4f0b-cbc5-22ca9a99cf7e"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# target compression rate\n",
    "bit_per_image = tf.placeholder(tf.int32, shape=())\n",
    "Pe = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "\n",
    "# Network parameters\n",
    "hidden_encoder_1 = 500\n",
    "hidden_encoder_2 = 250\n",
    "hidden_encoder_3 = 120\n",
    "\n",
    "hidden_decoder_1 = 120\n",
    "hidden_decoder_2 = 250\n",
    "hidden_decoder_3 = 500\n",
    "\n",
    "\n",
    "training_data = tf.placeholder(tf.float32, [None, image_size*image_size])\n",
    "\n",
    "valid_data = tf.constant(x_test_flat, dtype=tf.float32)\n",
    "\n",
    "\n",
    "weights = { 'We1' : tf.Variable(tf.truncated_normal([image_size*image_size, hidden_encoder_1], stddev=0.1)),\n",
    "            'We2' : tf.Variable(tf.truncated_normal([hidden_encoder_1, hidden_encoder_2], stddev=0.1)),\n",
    "            'We3' : tf.Variable(tf.truncated_normal([hidden_encoder_2, hidden_encoder_3], stddev=0.1)),\n",
    "            'We4' : tf.Variable(tf.truncated_normal([hidden_encoder_3, bit_per_image], stddev=0.1), validate_shape=False),\n",
    "            'Wd1' : tf.Variable(tf.truncated_normal([bit_per_image, hidden_decoder_1], stddev=0.1), validate_shape=False),\n",
    "            'Wd2' : tf.Variable(tf.truncated_normal([hidden_decoder_1, hidden_decoder_2], stddev=0.1)),\n",
    "            'Wd3' : tf.Variable(tf.truncated_normal([hidden_decoder_2, hidden_decoder_3], stddev=0.1)),\n",
    "            'Wd4' : tf.Variable(tf.truncated_normal([hidden_decoder_3, image_size*image_size], stddev=0.1)),\n",
    "          }\n",
    "\n",
    "biases = {  'be1' : tf.Variable(tf.truncated_normal([hidden_encoder_1], stddev=0.1)),\n",
    "            'be2' : tf.Variable(tf.truncated_normal([hidden_encoder_2], stddev=0.1)),\n",
    "            'be3' : tf.Variable(tf.truncated_normal([hidden_encoder_3], stddev=0.1)),\n",
    "            'be4' : tf.Variable(tf.truncated_normal([bit_per_image], stddev=0.1), validate_shape=False),\n",
    "            'bd1' : tf.Variable(tf.truncated_normal([hidden_decoder_1], stddev=0.1)),\n",
    "            'bd2' : tf.Variable(tf.truncated_normal([hidden_decoder_2], stddev=0.1)),\n",
    "            'bd3' : tf.Variable(tf.truncated_normal([hidden_decoder_3], stddev=0.1)),\n",
    "            'bd4' : tf.Variable(tf.truncated_normal([image_size*image_size], stddev=0.1)),\n",
    "          }\n",
    "\n",
    "def binarizer(input):\n",
    "    prob = tf.truediv(tf.add(input, 1.0), 2.0)\n",
    "    bernoulli = tf.distributions.Bernoulli(probs=prob, dtype=tf.float32)\n",
    "    return 2*bernoulli.sample() - 1\n",
    "\n",
    "def binarizer_deterministic(input):\n",
    "    return tf.sign(input)\n",
    "\n",
    "def encoder(batch):\n",
    "    temp = tf.nn.elu(tf.matmul(batch, weights['We1']) + biases['be1'])\n",
    "    temp = tf.nn.elu(tf.matmul(temp, weights['We2']) + biases['be2'])\n",
    "    temp = tf.nn.elu(tf.matmul(temp, weights['We3']) + biases['be3'])\n",
    "    output = tf.nn.softsign(tf.matmul(temp, weights['We4']) + biases['be4'])\n",
    "    return output\n",
    "\n",
    "def decoder(batch):\n",
    "    temp = tf.nn.elu(tf.matmul(batch, weights['Wd1']) + biases['bd1'])\n",
    "    temp = tf.nn.elu(tf.matmul(temp, weights['Wd2']) + biases['bd2'])\n",
    "    temp = tf.nn.elu(tf.matmul(temp, weights['Wd3']) + biases['bd3'])\n",
    "    output = tf.nn.sigmoid(tf.matmul(temp, weights['Wd4']) + biases['bd4'])\n",
    "    return output\n",
    "\n",
    "encoded = encoder(training_data)\n",
    "# random binarization in training\n",
    "ti = tf.identity(encoded)\n",
    "compressed = ti + tf.stop_gradient(binarizer(encoded) - ti)\n",
    "\n",
    "# add error pattern\n",
    "error_tensor = tf.distributions.Bernoulli(probs = Pe * tf.ones_like(compressed), dtype=tf.float32).sample() \n",
    "received = tf.math.multiply( compressed, 1 - 2*error_tensor)\n",
    "\n",
    "reconstructed = decoder(received)\n",
    "\n",
    "encoded_test = encoder(valid_data)\n",
    "compressed_test = binarizer_deterministic(encoded_test)\n",
    "error_tensor_test = tf.distributions.Bernoulli(probs = Pe * tf.ones_like(compressed_test), dtype=tf.float32).sample()\n",
    "received_test = tf.math.multiply( compressed_test, 1 - 2*error_tensor_test )\n",
    "reconstructed_test = decoder(received_test)\n",
    "loss_test = tf.reduce_mean(tf.square(valid_data - reconstructed_test))\n",
    "\n",
    "\n",
    "signal_test = tf.reduce_sum(tf.square(valid_data))\n",
    "noise_test = tf.reduce_sum(tf.square(valid_data - reconstructed_test))\n",
    "\n",
    "SNR = 10.0*(tf.log(signal_test) - tf.log(noise_test))/tf.log(tf.constant(10.0))\n",
    "\n",
    "loss = tf.losses.mean_squared_error(training_data, reconstructed)\n",
    "#loss = tf.reduce_mean(tf.square(training_data - reconstructed))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-uMqsfxa86bY"
   },
   "outputs": [],
   "source": [
    "def get_batch(x, batch_size):\n",
    "    idxs = np.random.randint(0, x.shape[0], (batch_size))\n",
    "    return np.array([np.reshape(x[k,:,:], image_size*image_size) for k in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweep among different bit per image values and different error probabilities. The results are saved in a text file that can be used to plot figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "I8OBiNu586be",
    "outputId": "8243c7a0-02c6-41c6-cefc-a5cbc977bd42"
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "Pe_range = np.array([0, 0.01, 0.1, 0.2])\n",
    "bit_range = np.array([5, 10, 20, 30, 40, 50, 60, 70, 80, 100])\n",
    "\n",
    "SNR_result = np.zeros( (len(Pe_range), len(bit_range)) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Pe_range)):\n",
    "    for j in range(len(bit_range)):\n",
    "\n",
    "        best_SNR = -9999;\n",
    "        print('Initializing ....')\n",
    "        # Create session and initialize all variables\n",
    "        session = tf.InteractiveSession()\n",
    "        session.run(init, feed_dict = { bit_per_image : bit_range[j]})\n",
    "        print('done')\n",
    "        # Training loop\n",
    "        for it in range(100000):  \n",
    "            mini_batch = get_batch(x_train, batch_size)\n",
    "\n",
    "            session.run(train_step, feed_dict = { training_data : mini_batch, bit_per_image : bit_range[j], Pe: Pe_range[i] })    \n",
    "\n",
    "    \n",
    "            if it % 500 == 0:\n",
    "                cur_SNR = SNR.eval(feed_dict = { bit_per_image : bit_range[j], Pe: Pe_range[i] }) \n",
    "                if cur_SNR > best_SNR:\n",
    "                    best_SNR = cur_SNR\n",
    "              \n",
    "            if it % 10000 == 0:            \n",
    "                print('Pe = %1.2f, bits = %d, It %d: (best SNR: %1.4f dB)' % (Pe_range[i], bit_range[j], it, best_SNR))\n",
    "        \n",
    "        SNR_result[i,j] = best_SNR\n",
    "        print('Finished learning for e = %1.2f, bits = %d. Best SNR: %1.4f' % (Pe_range[i], bit_range[j], best_SNR))\n",
    "        \n",
    "        session.close()\n",
    "np.savetxt('SNR_result.txt', SNR_result, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "g2BJE9pW86bl",
    "outputId": "e26cb91f-44fc-447b-9b0e-a95f287e4f37"
   },
   "outputs": [],
   "source": [
    "valid_images =  reconstructed_test.eval(feed_dict = { bit_per_image : 20, Pe: 0.0 })\n",
    "\n",
    "\n",
    "valid_binary = 0.5*(1 - compressed_test.eval())   # from bipolar (BPSK) to binary\n",
    "# show 8 images and their reconstructed versions\n",
    "plt.figure(figsize=(16,4))\n",
    "idxs = np.random.randint(x_test.shape[0],size=8)\n",
    "for k in range(8):\n",
    "    plt.subplot(2,8,k+1)    \n",
    "    plt.imshow(np.reshape(x_test_flat[idxs[k]], (image_size,image_size)), interpolation='nearest', cmap='binary')    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.subplot(2,8,k+1+8)\n",
    "    plt.imshow(np.reshape(valid_images[idxs[k]], (image_size,image_size)), interpolation='nearest', cmap='binary')    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    \n",
    "# print binary data of the images\n",
    "for k in range(8):\n",
    "    print('Image %d: ' % (k+1), valid_binary[idxs[k],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWXHvbTD86b2"
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder_Compression_Binarizer_Sweep.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
